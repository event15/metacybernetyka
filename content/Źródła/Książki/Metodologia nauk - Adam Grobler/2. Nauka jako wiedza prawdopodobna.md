- Metoda indukcji eliminacyjnej miała na celu przekształcenie zawodnego wnioskowania indukcyjnego w coś równie niezawodnego jak wnioskowanie dedukcyjne. Okazuje się jednak, że nawet najbogatsze, lecz z natury rzeczy skończone świadectwo empiryczne nie może wystarczyć do wyczerpującego uzasadnienia żadnej hipotezy uniwersalnej. (s. 33)
- Świadectwo empiryczne zatem przynajmniej częściowo uzasadnia wybór hipotez. Takie rozumowanie prowadzi do stanowiska nazywanego przez Lakatosa[^1] **słabym justyfikacjonizmem**. (s. 33)
- Żadna hipoteza nigdy nie jest wyczerpująco uzasadniona, ale może być lepiej lub gorzej potwierdzona przez świadectwo. Potwierdzenie jest więc stopniowalne (s. 34)
- Jak mierzyć stopień potwierdzenia? Są dwa poważne argumenty, aby stopień potwierdzenia hipotezy traktować jako prawdopodobieństwo jej prawdziwości, dokładniej, prawdopodobieństwo warunkowe ze względu na świadectwo. (s. 34)
	- Po pierwsze, za pomocą pojęcia prawdopodobieństwa warunkowego można zdefiniować relację między zdaniami[^2] - z których jedno wyraża hipotezę, a drugie świadectwo - będącą uogólnieniem zwykłej implikacji. Mianowicie: równość $P(H|E) = 1$ znaczy tyle, że jeżeli zachodzi $E$ ($E$ jest zdaniem prawdziwym), to $P(H) = 1$, czyli $H$ jest pewne[^3], a zatem prawdziwe. Innymi słowy, $P(H|E) = 1$ jest praktycznie równoważne implikacji $E \implies H$. Z kolei równość $P(H|E) = 0$ znaczy tyle, że jeżeli zachodzi $E$ ($E$ jest zdaniem prawdziwym), to $P(H) = 0$, czyli jest niemożliwe[^4], to znaczy fałszywe. Innymi słowy, $P(H|E) = 0$ jest w zasadzie równoważne implikacji $E \implies \lnot H$. Przypadki pośrednie, to znaczy $P(H|E) = r, 0 < r < 1$, reprezentują więc sytuację, w której $E$ "częściowo implikuje" $H$, ale ją niejako sugeruje: im większe $r$, tym bardziej prawdopodobne, że $H$ jest prawdziwe. Wydaje się, że świadectwo empiryczne wchodzi w tego rodzaju relacje z hipotezami: nie implikuje ich, lecz uprawdopodabnia.
	- Po drugie, wydaje się, że za pomocą pojęcia prawdopodobieństwa można należycie określić **stopień racjonalnego przekonania** o prawdziwości hipotezy. Z braku wyczerpujących dowodów uczony nigdy nie może być pewny swoich hipotez. Stąd jednak nie wynika, że musi, jak starożytny sceptyk, przestrzegać zasady równowagi sądzenia. Przeciwnie, świadectwa słusznie skłaniają uczonych do dyskryminacji hipotez: uczeni są w mniejszym lub większym stopniu przekonani o ich prawdziwości.
- Pytanie brzmi: co to znaczy, że ktoś jest przekonany w stopniu $r$ o prawdziwości $H$? Stopień przekonania najlepiej jest mierzyć skłonnością do działania na podstawie danej hipotezy. (s. 35)
- Warunkiem racjonalności gracza zawierającego zakłady jest to, by przystępując do systemu zakładów, nie przegrał. (s. 35)
- Okazuje się, że kompletny system zakładów (to jest taki, w którym gracz obstawia wszystkie możliwe wyniki) nie jest systemem holenderskim wtedy i tylko wtedy, gdy układ stopni przekonania gracza, mierzony jest ilorazem zawieranych przez niego zakładów, spełnia aksjomaty rachunku prawdopodobieństwa[^5]. (s. 35)
- Z powyższych rozważań wynika, że wyjściowy układ stopni przekonania powinien spełniać aksjomaty rachunku prawdopodobieństwa, a następnie być modyfikowany pod wpływem świadectwa, również zgodnie z aksjomatami rachunku prawdopodobieństwa. Ten drugi warunek jest spełniony, jeżeli stopień przekonania o prawdziwości hipotezy ze względu na dane świadectwo ujmuje się jako prawdopodobieństwo warunkowe. (s. 36)
- Kłopot polega na tym, że samo pojęcie prawdopodobieństwa nie jest całkiem jasne.
- Z czysto matematycznego punktu widzenia prawdopodobieństwo jest unormowaną miarą addytywną określoną na pewnym zbiorze, to jest spełniającą pewne dodatkowe warunki funkcją o wartościach z przedziału $[0,1]$, określoną na spełniającym pewne warunki podzbiorze zbioru podzbiorów pewnego zbioru.(s. 36)
- Natomiast z filozoficznego punktu widzenia potrzebna jest jakaś interpretacja umożliwiająca wyjaśnienie, dlaczego to matematyczne pojęcie ma zastosowanie do rozwiązywania określonego typu problemów. W wypadku zastosowania do problemu indukcji rozpatrywano trzy interpretacje: częstościową, logiczną i subiektywną. (s. 36)
- **Interpretacja częstościowa** nawiązuje do tak zwanej klasycznej definicji prawdopodobieństwa[^6], wyrażającej prostą intuicję, wedle której prawdopodobieństwo interesującego nas zdarzenia jest miarą jego średniej częstości w nieograniczenie długiej serii starzeń określonego typu. (s. 36)
- Nieco zagadkowe pojęcie **częstości**, nie dość, że średniej, to jeszcze w nieograniczenie długiej serii zdarzeń, ma całkiem ścisłą, matematyczną definicję. Mianowicie: nieograniczenie długą serię zdarzeń można przedstawić w formie nieskończonego ciągu skończonych ciągów $n$ początkowych zdarzeń tej serii. W każdej takiej skończonej podserii częstość - nazwijmy ją względną - interesującego nas zdarzenia można określić po prostu jako stosunek liczby wystąpień tego zdarzenia w danej podserii do długości tej podserii na przykład stosunek liczby reszek do $n$ - liczby rzutów w podserii $n$ początkowych rzutów nieograniczenie długiej serii rzutów monetą. (s. 36, s. 37)
- W szczęśliwym wypadku, w którym ciąg częstości względnych jest zbieżny, jego granicę można nazwać średnią częstością interesującego nas zdarzenia. W pozostałych wypadkach średnia częstość nie jest określona. (s. 37)
- Interpretację częstościową prawdopodobieństwa próbował zastosować do budowy logiki indukcji Hans Reichenbach[^7]. Ten pomysł ma jednak wiele wad. Po pierwsze wymaga traktowania hipotez jako zdań eliptycznych o prawdopodobieństwie. Znaczy to, że hipotezę postaci $(\forall x)[W(x) \to Z(x)]$  należy rozumieć nie dosłownie (każdy przedmiot, który znajdzie się w warunkach $W$, zachowa się w sposób $Z$), lecz przenośnie: przedmiot, który znajdzie się w warunkach $W$, prawdopodobnie zachowa się w sposób $Z$. Po drugie, na co wskazywał von Mises[^8], wartości prawdopodobieństwa w interpretacji częstościowej można szacować jedynie na podstawie doświadczenia. Same szacunki zatem mają charakter hipotez indukcyjnych. Wobec tego stosowanie pojęcia prawdopodobieństwa w interpretacji częstościowej do uzasadniania procedur indukcyjnych zakrawa na błędne koło. Po trzecie, z czysto matematycznego punktu widzenia średnia częstość zależy od kolejności wyrazów ciągu względnych częstości. To znaczy, że przygodna zmiana kolejności rejestrowania świadectw, bez zmiany samych świadectw, może mieć istotny wpływ na ocenę prawdopodobieństwa hipotezy. (s. 37)
- Na idei prawdopodobieństwa logicznego opiera się sformułowany przez Carnapa program logiki indukcji. Prawdopodobieństwo warunkowe zdania $H$ ze względu na zdanie $E$ jest w tym sensie prawdopodobieństwem logicznym, że zależy od tak zwanego prawdopodobieństwa *a priori* (bez dowodu) zdań $H$ i $E$ oraz czysto logicznego związku między nimi, związku będącego uogólnieniem klasycznej implikacji. Własności tego związku można zatem opisać za pomocą odpowiedniego rachunku logicznego. (s. 37, s.38)
- Konstrukcja takiego rachunku, sformułowana w *Logical Foundations of Probability*[^9], przebiega następująco.
	- Punktem wyjścia jest monadyczny język rachunku predykatów pierwszego rzędu, to jest język, którego alfabet obejmuje:
		- zmienne i stałe indywiduowe: $x, y, z, \dots, a_1, \dots, a_N$,
		- predykaty jednoargumentowe: $P_1, \dots, P_r$,
		- spójniki logiczne: $\lnot, \land, \lor, \to (\implies), \leftrightarrow (\iff)$,
		- kwantyfikatory: $\exists, \forall$ 
	- Dodatkowo zakłada się, że w języku występują nazwy własne wszystkich elementów jego uniwersum i każdy element uniwersum ma tylko jedną nazwę. Innymi słowy, skoro w języku znajduje się $N$ stałych indywiduowych, uniwersum języka składa się z $N$ indywiduów. Ponadto o predykatach $P_1, \dots, P_r$ zakłada się, że są proste, to znaczy żaden z nich nie daje się zdefiniować za pomocą innych predykatów. Natomiast za pomocą predykatów prostych można zdefiniować szczególną klasę predykatów, tak zwanych Q-predykatów: 
	  $$Q_i(x) \iff \pm P_1 \land \pm P_2 (x) \land \dots \land \pm P_r(x), i = 1, \dots, k, k = 2^r$$
	  gdzie symbol $\pm P_j(x)$ oznacza bądź $P_j(x)$, bądź $\lnot P_j(x), j = 1, \dots, r$.
	  Szczególna rola Q-predykatów polega na tym, że gdy w miejsce zmiennej $x$ podstawić nazwę określonego indywiduum, powiedzmy: $a$, Q-predykat orzeka o nim, które z własności oznaczonych za pomocą predykatów elementarnych mu przysługują, a które nie. Innymi słowy, podaje jego wyczerpujący opis - wyczerpujący ze względu na siłę wyrazu rozpatrywanego języka. Naturalnie, każdy Q-predykat podaje inny opis $a$, a więc tylko jeden z nich może być prawdziwy. W ten sposób Q-predykaty wyznaczają wyczerpujący i rozłączny podział uniwersum języka na Q-zbiory: zbiory "jednakowych" indywiduów, to jest indywiduów spełniających ten sam Q-predykat. Każdemu możliwemu podziałowi uniwersum na Q-zbiory można przypisać ciąg Q-liczb, $N_1, \dots, N_k, (N_1 + \dots + N_k = N)$, określających liczebność poszczególnych Q-zbiorów, czyli, innymi słowy, rozkład statystyczny indywiduów na poszczególne Q-zbiory. Za pomocą Q-predykatów można zbudować szczególnego rodzaju zdania, zwane opisami indywiduowymi. Mają one postać następującą: 
	  $$ S_{i} \iff Q_{i_{1}}(a_{i}) \land \dots \land Q_{i_{N}}(a_{N}), i = 1, \dots, k^{N}, i_{j} = 1, \dots, k.$$
	  Zdanie tego typu jest wyczerpującym opisem uniwersum, ponieważ jest koniunkcją wyczerpujących opisów wszystkich indywiduów. Każdy opis indywiduowy definiuje pewien "możliwy świat", to jest świat, o którym ten opis jest prawdziwy. W szczególności każdemu opisowi indywiduowemu jednoznacznie odpowiada pewien ciąg Q-liczb (ale nie na odwrót: różnym opisom indywiduowym może odpowiadać ten sam ciąg Q-liczb). Każde inne zdanie rozpatrywanego języka daje się przedstawić w postaci alternatywy opisów indywiduowych. Każde dwa opisy indywiduowe wykluczają się wzajemnie, co ma doniosłe znaczenie dla dalszej konstrukcji rachunku. Wystarczy mianowicie określić prawdopodobieństwo *a priori* dla wszystkich opisów, aby uznać - na mocy aksjomatu $P(A \lor B) = P(A) + P(B)$, gdy $A$ i $B$ się wykluczają - rozkład prawdopodobieństwa na zbiorze wszystkich zdań rozpatrywanego języka.


[^1]: Zob. I. Lakatos, *Falsyfikacja a metodologia naukowych programów badawczych* w: tenże, *Pisma z filozofii nauk empirycznych*, tłum. W. Sady, Warszawa 1995 (pierwodruk oryginału 1970)
[^2]: Czytelnik może być przyzwyczajony do tego, że prawdopodobieństwo określa się nie na zdaniach, ale na zdarzeniach pojmowanych jako zbiory. W istocie nie ma wielkiej różnicy: wystarczy zbiór zastąpić zdaniem będącym jego opisem, a operacje mnogościowe zastąpić logicznymi. W szczególności prawdopodobieństwo warunkowe hipotezy $H$ ze względu na świadectwo $E$ definiuje się wzorem: $P(H|E) = \frac{P(H \land E)}{P(E)}$.
[^3]: przy założeniu, ze przestrzeń prawdopodobieństwa jest skończona. W przeciwnym razie $P(H) = 1$ jest równoważne temu, że zbiór przypadków sprzyjających $nie-H$ jest miary zero (lecz może być niepusty).
[^4]: Dokładniej: zbiór przypadków sprzyjających $H$ jest miary zero (choć może być niepusty).
[^5]: Zanim Kołmogorow sformułował klasyczny układ aksjomatów, Thomas Bayes, jeden z pionierów rachunku prawdopodobieństwa, używał argumentu z holenderskiego systemu zakładów dla uzasadnienia swoich twierdzeń.
[^6]: Jest to dokładnie ta definicja, którą poznają uczniowie szkoły średniej: prawdopodobieństwo danego zdarzenia jest równe stosunkowi liczby elementarnych zdarzeń sprzyjających temu zdarzeniu do liczby wszystkich zdarzeń elementarnych.
[^7]: Zob. H. Reichenbach, *The Theory of Probability*, tłum. (na język angielski) E.H. Hutton, M. Reichenbach, Berkeley-Los Angeles 1949. Poszerzone wydanie wcześniejszego *Wahrscheinlichkeitslehre*, Leiden 1935.
[^8]: Zob. R. von Mises, *Probability, Statistics, and Truth*, Dover-New York 1957.
[^9]: R. Carnap, *Logical Foundations of Probability*, Chicago 1950